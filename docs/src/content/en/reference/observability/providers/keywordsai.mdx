---
title: "Reference: Keywords AI Integration | Mastra Observability Docs"
description: Documentation for integrating Keywords AI with Mastra, a observability platform for LLM applications.
---

This tutorial shows how to set up Keywords AI tracing with [Mastra](https://mastra.ai/) to monitor and trace your AI-powered applications.

We have built a pre-built example for you to get started quickly. You can find the code [here](https://github.com/Keywords-AI/keywordsai-example-projects/tree/main/mastra-ai-weather-agent).

Here's the tutorial about the Mastra Weather Agent example.

## Setup

### 1. Install Dependencies
```bash
pnpm install
```

### 2. Environment Variables

Copy the example environment file and add your API keys:

```bash
cp .env.local.example .env.local
```

Update .env.local with your credentials:
```bash .env.local
OPENAI_API_KEY=your-openai-api-key
KEYWORDSAI_API_KEY=your-keywordsai-api-key
KEYWORDSAI_BASE_URL=https://api.keywordsai.co
```

### 3. Run the Project

```bash
mastra dev
```
This opens the Mastra playground where you can interact with the weather agent.

## Observability
The project is configured with KeywordsAI telemetry in `src/mastra/index.ts`:

```typescript
telemetry: {
  serviceName: "keywordai-mastra-example",
  enabled: true,
  export: {
    type: "custom",
    exporter: new KeywordsAIExporter({
      apiKey: process.env.KEYWORDSAI_API_KEY,
      baseUrl: process.env.KEYWORDSAI_BASE_URL,
      debug: true,
    })
  }
}
```